\documentclass[11pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[margin=1in]{geometry}
\usepackage{forest}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{listings}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{enumitem}

% Define colors
\definecolor{foldercolor}{RGB}{70, 130, 180}
\definecolor{filecolor}{RGB}{60, 60, 60}
\definecolor{corecolor}{RGB}{220, 53, 69}
\definecolor{modelcolor}{RGB}{40, 167, 69}

\title{\textbf{Local Transformers Library Structure}\\
\large High-Level Architecture Overview}
\author{Qwen3-VL Project}
\date{\today}

\begin{document}

\maketitle
\tableofcontents
\newpage

% ============================================================================
\section{Overview}
% ============================================================================

The \texttt{local\_transformers/} directory contains a complete local copy of the Hugging Face Transformers library (version 4.57.1). This enables full control over model code for optimization, debugging, and customization without relying on external package installations.

\subsection{Key Statistics}
\begin{itemize}
    \item \textbf{Total Files:} $\sim$2,240 Python files
    \item \textbf{Model Architectures:} 300+ model families
    \item \textbf{Core Modules:} 15+ utility categories
    \item \textbf{Version:} 4.57.1 (Transformers)
\end{itemize}

% ============================================================================
\section{Top-Level Structure}
% ============================================================================

\begin{table}[h]
\centering
\begin{tabular}{@{}llp{8cm}@{}}
\toprule
\textbf{Directory/File} & \textbf{Type} & \textbf{Description} \\
\midrule
\texttt{\_\_init\_\_.py} & File & Package initialization, exports all public APIs \\
\texttt{models/} & Directory & All model architectures (300+ families) \\
\texttt{utils/} & Directory & Core utility functions and helpers \\
\texttt{generation/} & Directory & Text generation logic and strategies \\
\texttt{pipelines/} & Directory & High-level inference pipelines \\
\texttt{integrations/} & Directory & Third-party library integrations \\
\texttt{quantizers/} & Directory & Quantization implementations \\
\texttt{kernels/} & Directory & Custom CUDA/C++ kernels \\
\texttt{data/} & Directory & Data processing and collation \\
\texttt{commands/} & Directory & CLI commands \\
\texttt{distributed/} & Directory & Distributed training utilities \\
\texttt{onnx/} & Directory & ONNX export functionality \\
\texttt{sagemaker/} & Directory & AWS SageMaker integration \\
\texttt{loss/} & Directory & Loss function implementations \\
\bottomrule
\end{tabular}
\caption{Top-level directories in local\_transformers}
\end{table}

% ============================================================================
\section{Core Modules (Root Level Files)}
% ============================================================================

These files provide the foundational functionality used across all models.

\subsection{Model Infrastructure}
\begin{table}[h]
\centering
\begin{tabular}{@{}lp{9cm}@{}}
\toprule
\textbf{File} & \textbf{Purpose} \\
\midrule
\texttt{modeling\_utils.py} & Base \texttt{PreTrainedModel} class, weight loading, saving \\
\texttt{configuration\_utils.py} & Base \texttt{PretrainedConfig} class for model configs \\
\texttt{modeling\_outputs.py} & Standard output dataclasses (logits, hidden states) \\
\texttt{modeling\_layers.py} & Common layer implementations \\
\texttt{modeling\_attn\_mask\_utils.py} & Attention mask creation and manipulation \\
\texttt{modeling\_flash\_attention\_utils.py} & Flash Attention integration \\
\texttt{modeling\_rope\_utils.py} & Rotary Position Embedding (RoPE) utilities \\
\bottomrule
\end{tabular}
\caption{Core modeling infrastructure files}
\end{table}

\subsection{Tokenization}
\begin{table}[h]
\centering
\begin{tabular}{@{}lp{9cm}@{}}
\toprule
\textbf{File} & \textbf{Purpose} \\
\midrule
\texttt{tokenization\_utils.py} & Base tokenizer class (slow tokenizers) \\
\texttt{tokenization\_utils\_fast.py} & Fast tokenizer class (Rust-based) \\
\texttt{tokenization\_utils\_base.py} & Shared tokenizer base functionality \\
\bottomrule
\end{tabular}
\caption{Tokenization infrastructure}
\end{table}

\subsection{Processing (Vision/Audio)}
\begin{table}[h]
\centering
\begin{tabular}{@{}lp{9cm}@{}}
\toprule
\textbf{File} & \textbf{Purpose} \\
\midrule
\texttt{processing\_utils.py} & Multimodal processor base class \\
\texttt{image\_processing\_utils.py} & Image preprocessing utilities \\
\texttt{image\_processing\_utils\_fast.py} & Fast image processing \\
\texttt{image\_transforms.py} & Image transformation functions \\
\texttt{image\_utils.py} & Image loading and conversion \\
\texttt{video\_processing\_utils.py} & Video preprocessing utilities \\
\texttt{video\_utils.py} & Video loading and frame extraction \\
\texttt{audio\_utils.py} & Audio processing utilities \\
\texttt{feature\_extraction\_utils.py} & Feature extractor base class \\
\bottomrule
\end{tabular}
\caption{Multimodal processing files}
\end{table}

\subsection{Training Infrastructure}
\begin{table}[h]
\centering
\begin{tabular}{@{}lp{9cm}@{}}
\toprule
\textbf{File} & \textbf{Purpose} \\
\midrule
\texttt{trainer.py} & Main \texttt{Trainer} class for training loops \\
\texttt{trainer\_utils.py} & Training utility functions \\
\texttt{trainer\_pt\_utils.py} & PyTorch-specific training utilities \\
\texttt{trainer\_callback.py} & Callback system for training hooks \\
\texttt{trainer\_seq2seq.py} & Seq2Seq trainer variant \\
\texttt{training\_args.py} & \texttt{TrainingArguments} dataclass \\
\texttt{training\_args\_seq2seq.py} & Seq2Seq training arguments \\
\texttt{optimization.py} & Optimizers and schedulers \\
\bottomrule
\end{tabular}
\caption{Training infrastructure files}
\end{table}

\subsection{Other Core Files}
\begin{table}[h]
\centering
\begin{tabular}{@{}lp{9cm}@{}}
\toprule
\textbf{File} & \textbf{Purpose} \\
\midrule
\texttt{activations.py} & Activation functions (GELU, SiLU, etc.) \\
\texttt{cache\_utils.py} & KV-cache implementations for generation \\
\texttt{pytorch\_utils.py} & PyTorch utility functions \\
\texttt{dynamic\_module\_utils.py} & Dynamic module loading from Hub \\
\texttt{hf\_argparser.py} & Argument parser for dataclasses \\
\texttt{safetensors\_conversion.py} & SafeTensors format conversion \\
\bottomrule
\end{tabular}
\caption{Additional core utilities}
\end{table}

% ============================================================================
\section{Models Directory (\texttt{models/})}
% ============================================================================

The \texttt{models/} directory contains 300+ model architecture implementations. Each model family has its own subdirectory.

\subsection{Qwen Model Family (Primary Focus)}
\begin{table}[h]
\centering
\begin{tabular}{@{}lp{9cm}@{}}
\toprule
\textbf{Directory} & \textbf{Description} \\
\midrule
\texttt{qwen3\_vl/} & \textbf{Qwen3-VL} - Primary vision-language model \\
\texttt{qwen3\_vl\_moe/} & Qwen3-VL Mixture of Experts variant \\
\texttt{qwen3/} & Qwen3 base language model \\
\texttt{qwen3\_moe/} & Qwen3 MoE variant \\
\texttt{qwen2\_5\_vl/} & Qwen2.5-VL vision-language model \\
\texttt{qwen2\_vl/} & Qwen2-VL vision-language model \\
\texttt{qwen2/} & Qwen2 base language model \\
\texttt{qwen2\_moe/} & Qwen2 MoE variant \\
\texttt{qwen2\_audio/} & Qwen2 audio model \\
\texttt{qwen2\_5\_omni/} & Qwen2.5 omni-modal model \\
\texttt{qwen3\_omni\_moe/} & Qwen3 omni-modal MoE \\
\bottomrule
\end{tabular}
\caption{Qwen model family directories}
\end{table}

\subsection{Model Directory Structure}
Each model directory typically contains:
\begin{itemize}[noitemsep]
    \item \texttt{\_\_init\_\_.py} -- Module exports
    \item \texttt{configuration\_<model>.py} -- Model configuration class
    \item \texttt{modeling\_<model>.py} -- PyTorch model implementation
    \item \texttt{processing\_<model>.py} -- Multimodal processor (if applicable)
    \item \texttt{tokenization\_<model>.py} -- Tokenizer (if custom)
    \item \texttt{image\_processing\_<model>.py} -- Image processor (if applicable)
    \item \texttt{modular\_<model>.py} -- Modular/composable implementation
\end{itemize}

\subsection{Other Notable Model Families}
\begin{longtable}{@{}lp{9cm}@{}}
\toprule
\textbf{Category} & \textbf{Models} \\
\midrule
\endhead
\textbf{Vision-Language} & llava, llava\_next, llava\_onevision, blip, blip\_2, idefics, idefics2, idefics3, paligemma, pixtral, phi4\_multimodal \\
\textbf{Large Language} & llama, llama4, mistral, mixtral, gemma, gemma2, gemma3, phi, phi3, falcon, gpt2, gpt\_neox, opt, bloom \\
\textbf{Vision} & vit, clip, siglip, dinov2, sam, sam2, deit, swin, convnext \\
\textbf{Audio/Speech} & whisper, wav2vec2, hubert, speecht5, moshi \\
\textbf{Encoder-Decoder} & t5, bart, mbart, pegasus, led \\
\textbf{Specialized} & deepseek\_v2, deepseek\_v3, jamba, mamba, mamba2, rwkv \\
\bottomrule
\caption{Notable model families by category}
\end{longtable}

% ============================================================================
\section{Generation Directory (\texttt{generation/})}
% ============================================================================

Handles text generation strategies and utilities.

\begin{table}[h]
\centering
\begin{tabular}{@{}lp{9cm}@{}}
\toprule
\textbf{File/Directory} & \textbf{Purpose} \\
\midrule
\texttt{configuration\_utils.py} & Generation configuration (\texttt{GenerationConfig}) \\
\texttt{logits\_process.py} & Logits processors (temperature, top-k, top-p, etc.) \\
\texttt{stopping\_criteria.py} & Stopping criteria for generation \\
\texttt{beam\_search.py} & Beam search implementation \\
\texttt{beam\_constraints.py} & Constrained beam search \\
\texttt{candidate\_generator.py} & Speculative decoding candidates \\
\texttt{streamers.py} & Token streaming for real-time output \\
\texttt{utils.py} & Generation utility functions \\
\texttt{watermarking.py} & Text watermarking for generated content \\
\texttt{continuous\_batching/} & Continuous batching for serving \\
\bottomrule
\end{tabular}
\caption{Generation module contents}
\end{table}

% ============================================================================
\section{Pipelines Directory (\texttt{pipelines/})}
% ============================================================================

High-level inference APIs for common tasks.

\begin{table}[h]
\centering
\begin{tabular}{@{}lp{9cm}@{}}
\toprule
\textbf{File} & \textbf{Task} \\
\midrule
\texttt{text\_generation.py} & Text generation pipeline \\
\texttt{image\_text\_to\_text.py} & Vision-language inference \\
\texttt{image\_to\_text.py} & Image captioning \\
\texttt{visual\_question\_answering.py} & VQA pipeline \\
\texttt{image\_classification.py} & Image classification \\
\texttt{object\_detection.py} & Object detection \\
\texttt{image\_segmentation.py} & Semantic/instance segmentation \\
\texttt{automatic\_speech\_recognition.py} & ASR/transcription \\
\texttt{text\_classification.py} & Text classification \\
\texttt{question\_answering.py} & Extractive QA \\
\texttt{fill\_mask.py} & Masked language modeling \\
\texttt{token\_classification.py} & NER, POS tagging \\
\texttt{depth\_estimation.py} & Monocular depth estimation \\
\texttt{zero\_shot\_classification.py} & Zero-shot text classification \\
\texttt{zero\_shot\_image\_classification.py} & Zero-shot image classification \\
\bottomrule
\end{tabular}
\caption{Available inference pipelines}
\end{table}

% ============================================================================
\section{Integrations Directory (\texttt{integrations/})}
% ============================================================================

Third-party library integrations for optimization and acceleration.

\begin{table}[h]
\centering
\begin{tabular}{@{}lp{9cm}@{}}
\toprule
\textbf{File} & \textbf{Integration} \\
\midrule
\texttt{flash\_attention.py} & Flash Attention 2 \\
\texttt{flex\_attention.py} & PyTorch Flex Attention \\
\texttt{sdpa\_attention.py} & Scaled Dot-Product Attention \\
\texttt{accelerate.py} & Hugging Face Accelerate \\
\texttt{deepspeed.py} & DeepSpeed integration \\
\texttt{fsdp.py} & Fully Sharded Data Parallel \\
\texttt{peft.py} & Parameter-Efficient Fine-Tuning \\
\texttt{bitsandbytes.py} & 8-bit/4-bit quantization \\
\texttt{awq.py} & AWQ quantization \\
\texttt{quanto.py} & Quanto quantization \\
\texttt{hqq.py} & Half-Quadratic Quantization \\
\texttt{ggml.py} & GGML/GGUF format support \\
\texttt{tensor\_parallel.py} & Tensor parallelism \\
\texttt{tpu.py} & TPU support \\
\bottomrule
\end{tabular}
\caption{Third-party integrations}
\end{table}

% ============================================================================
\section{Quantizers Directory (\texttt{quantizers/})}
% ============================================================================

Quantization implementations for model compression.

\begin{table}[h]
\centering
\begin{tabular}{@{}lp{9cm}@{}}
\toprule
\textbf{File} & \textbf{Quantization Method} \\
\midrule
\texttt{quantizer\_bnb\_4bit.py} & BitsAndBytes 4-bit (NF4, FP4) \\
\texttt{quantizer\_bnb\_8bit.py} & BitsAndBytes 8-bit \\
\texttt{quantizer\_gptq.py} & GPTQ quantization \\
\texttt{quantizer\_awq.py} & AWQ quantization \\
\texttt{quantizer\_quanto.py} & Quanto quantization \\
\texttt{quantizer\_hqq.py} & Half-Quadratic Quantization \\
\texttt{quantizer\_fbgemm\_fp8.py} & FBGEMM FP8 \\
\texttt{quantizer\_torchao.py} & TorchAO quantization \\
\texttt{quantizer\_aqlm.py} & AQLM quantization \\
\texttt{quantizer\_bitnet.py} & BitNet 1-bit quantization \\
\bottomrule
\end{tabular}
\caption{Quantization implementations}
\end{table}

% ============================================================================
\section{Utils Directory (\texttt{utils/})}
% ============================================================================

Core utility functions and helpers.

\begin{table}[h]
\centering
\begin{tabular}{@{}lp{9cm}@{}}
\toprule
\textbf{File} & \textbf{Purpose} \\
\midrule
\texttt{import\_utils.py} & Lazy imports, optional dependency handling \\
\texttt{hub.py} & Hugging Face Hub interactions \\
\texttt{logging.py} & Logging configuration \\
\texttt{generic.py} & Generic utility functions \\
\texttt{chat\_template\_utils.py} & Chat template processing \\
\texttt{quantization\_config.py} & Quantization configuration classes \\
\texttt{peft\_utils.py} & PEFT-related utilities \\
\texttt{backbone\_utils.py} & Backbone model utilities \\
\texttt{constants.py} & Library constants \\
\texttt{deprecation.py} & Deprecation warnings \\
\texttt{dummy\_*.py} & Dummy objects for optional dependencies \\
\bottomrule
\end{tabular}
\caption{Utility module contents}
\end{table}

% ============================================================================
\section{Kernels Directory (\texttt{kernels/})}
% ============================================================================

Custom CUDA and C++ kernels for specific operations.

\begin{table}[h]
\centering
\begin{tabular}{@{}lp{9cm}@{}}
\toprule
\textbf{Directory} & \textbf{Purpose} \\
\midrule
\texttt{deta/} & Deformable attention CUDA kernels \\
\texttt{falcon\_mamba/} & Falcon Mamba selective scan kernels \\
\texttt{mra/} & Multi-Resolution Attention kernels \\
\texttt{rwkv/} & RWKV WKV operation kernels \\
\texttt{yoso/} & YOSO fast LSH cumulation kernels \\
\bottomrule
\end{tabular}
\caption{Custom CUDA/C++ kernels}
\end{table}

% ============================================================================
\section{Data Directory (\texttt{data/})}
% ============================================================================

Data processing and collation utilities.

\begin{table}[h]
\centering
\begin{tabular}{@{}lp{9cm}@{}}
\toprule
\textbf{File/Directory} & \textbf{Purpose} \\
\midrule
\texttt{data\_collator.py} & Data collators for batching \\
\texttt{datasets/} & Dataset loading utilities (GLUE, SQuAD, LM) \\
\texttt{processors/} & Data processors for specific tasks \\
\texttt{metrics/} & Evaluation metrics \\
\bottomrule
\end{tabular}
\caption{Data processing utilities}
\end{table}

% ============================================================================
\section{Key Files for Qwen3-VL Development}
% ============================================================================

For Qwen3-VL optimization work, focus on these key files:

\subsection{Primary Model Files}
\begin{enumerate}
    \item \texttt{models/qwen3\_vl/modeling\_qwen3\_vl.py} -- Main model implementation
    \item \texttt{models/qwen3\_vl/configuration\_qwen3\_vl.py} -- Model configuration
    \item \texttt{models/qwen3\_vl/processing\_qwen3\_vl.py} -- Multimodal processor
    \item \texttt{models/qwen3\_vl/image\_processing\_qwen3\_vl.py} -- Image preprocessing
\end{enumerate}

\subsection{Core Infrastructure}
\begin{enumerate}
    \item \texttt{modeling\_utils.py} -- Base model class
    \item \texttt{modeling\_flash\_attention\_utils.py} -- Flash attention
    \item \texttt{modeling\_rope\_utils.py} -- RoPE implementation
    \item \texttt{cache\_utils.py} -- KV-cache for generation
    \item \texttt{generation/} -- Text generation logic
\end{enumerate}

\subsection{Optimization-Related}
\begin{enumerate}
    \item \texttt{quantizers/} -- Quantization implementations
    \item \texttt{integrations/flash\_attention.py} -- Flash Attention
    \item \texttt{integrations/bitsandbytes.py} -- 4-bit/8-bit quantization
\end{enumerate}

% ============================================================================
\section{Dependency Graph}
% ============================================================================

\begin{verbatim}
local_transformers/
├── __init__.py (exports all public APIs)
│
├── Core Infrastructure
│   ├── modeling_utils.py ─────────────────┐
│   ├── configuration_utils.py ────────────┼── Used by ALL models
│   ├── processing_utils.py ───────────────┤
│   └── tokenization_utils*.py ────────────┘
│
├── models/
│   └── qwen3_vl/
│       ├── modeling_qwen3_vl.py ──────────┬── Imports from core
│       ├── configuration_qwen3_vl.py ─────┤
│       └── processing_qwen3_vl.py ────────┘
│
├── generation/ ───────────────────────────── Used for inference
│
├── integrations/ ─────────────────────────── Optional accelerations
│
└── quantizers/ ───────────────────────────── Optional compression
\end{verbatim}

% ============================================================================
\section{Summary}
% ============================================================================

The \texttt{local\_transformers/} directory provides a complete, self-contained copy of the Transformers library. Key points:

\begin{itemize}
    \item \textbf{Modular Design:} Each model family is isolated in its own directory
    \item \textbf{Shared Infrastructure:} Core utilities are reused across all models
    \item \textbf{Extensible:} Easy to add new integrations or modify existing code
    \item \textbf{Self-Contained:} No external Transformers installation required
\end{itemize}

For Qwen3-VL optimization, focus primarily on:
\begin{enumerate}
    \item \texttt{models/qwen3\_vl/} -- The main model code
    \item \texttt{modeling\_utils.py} -- Base class functionality
    \item \texttt{generation/} -- Text generation optimization
    \item \texttt{quantizers/} -- Model compression
\end{enumerate}

\end{document}
